date: 2020-02-05
title:  Замечания по организации обработки растров
tags: Remote Sensing, GEE, GRASS, TensorFlow
Category: Raster Processing

По результатам работы над поиском водных объектов хочется оставить несколько замечаний, касающихся удобств/неудобств обработки большого числа космосьемки
при помощи того или иного ПО.

## Общая характеристика обработки 

### Особенности методики
[Методика поиска водных объектов]({filename}/2019-12-16-Water.md) имеет несколько особенностей, характерных для конкретно этой задачи.

 1. Активная работа с различными каналами по различным формулам. Имеется в виду, что, к примеру, в отличие от классических методов машинного обучения
 (нейросети, деревья решений, логистической регрессии и т.п.) в этой методике каждый канал обрабатывается по своему. Другими словами, в методике нет схемы обработки, единой для
 всех каналов такой, к примеру, как умножение матриц для регрессий/нейросетей или единообразного разбиения пространства признаков деревьями.
 2. Групповая обработка пикселей: согласно методике, следует анализировать не только отдельные пиксели или скользящие окна, но и группы связанных пикселей, то есть
 по сути требуется сначала произвести сегментацию, а затем в каждом выделенном участке собарать зональные статистики и передать их на следующий этап обработки.
 3. Хотя сама методика довольно проста, но она оперирует параметрами, которые подбирались авторами "на глаз" и на другую территорию и (главное!) для другого сенсора;
 поэтому для того чтобы получить хороший результат в наших условиях требуется оптимизация параметров алгоритма на наших данных.

### Особенности данных
Помимо специфических требований конкретной методики, возникают также дополнительные ограничения, вытекающие из необходимости обрабатывать большую территорию. В итоге это
приводит к следующим особенностям:

 1. Большое количество данных: в область интересов попадает свыше 13 тыс. сцен Sentinel-2 (за два интересующих нас года, причем, это только летних снимков).
 2. Большая территория влечет за собой большое разнообразие ландшафтов, отдельное удовольствие доставляет не только широтная, но и высотная поясность; в
 итоге нельзя работать только в одном "углу" области интересов, приходится экспериментировать сразу на всем объеме.
 3. Большая территория подразумевает перепроецирование исходных сцен, т.к. космосьемка приходит в разных проекциях в зависимости от места съемки;
 4. Чтобы не "гонять" тестовые алгоритмы на слишком больших данных удобно менять разрешение снимков "на лету", что позволяет снизить количество обрабатываемых данных
 в ходе экспериментов (т.е. огрубить снимки и быстро прикинуть результат).


### Вывод
Идеальный инструмент для этой задачи должен уметь:

1. Обрабатывать десятки террабайт космоснимков.
2. Организовывать удобную работу с отдельными каналами (растровую алгебру, аггрегирование и прочее).
3. Считать зональные статистики.
4. Позволять оптимизацию параметров.
5. Стандартные ГИСовские штучки - перепроецирование, смена разрешения и прочие классические вещи.
6. Возможность использования того или иного языка программирования, чтобы склеивать между собой различные этапы и для написания скриптов.
7. (не обязательно, но желательно) Развитая библиотека уже готовых методов обработки, в частности классификаторов и оптимизаторов.



## Работа в Google EarthEngine
GEE на первый взгляд устраивает всем, особенно подкупает то, что в нем из коробки организован доступ к данным ДЗЗ и не требуется предварительное выкачивание
снимков. Также большое преимущество - скорость их обработки. Есть недостатки - лимиты на вычисления, в которые нет-нет, да и упираешься, в результате приходится
придумывать обходные пути (но это условный недостаток, т.к. лимиты есть в любых условиях).

Главная проблема GEE -- то, что у него очень ограничена возможность работы с зональной статистикой. GEE хранит данные у себя на серверах в виде тайлов 256x256 пикселей
в итоге для того, чтобы посчитать зональную статистику есть два пути:

* использовать функцию ee.Image.reduceConnectedComponents(), но она может работать только с объектами (зонами), протяженностью не более 256 пикселей; все, что выше - будет сброшено
в No-Data;
* если предыдуший вариант не устраивает, можно произвести векторизацию зон через функцию ee.Image.reduceToVectors() и считать статистики внутри векторных данных,
однако на большом объеме пикселей эта функция не будет работать из-за нехватки памяти (приходится или уменьшать территорию, или снижать разрешение).

Итак GEE - очень хороший кандидат, но в данном конкретном случае все портит проблема зональной статистики.


## Связка TensorFlow и GEE

Конечно, немного странно писать тут про TensorFlow, поскольку TF предназначен для других целей. Но упоминаю о нем, т.к. модели TF можно использовать напрямую в GEE,
что сильно расширяет возможности GEE (и частично снимает проблему зональных статистик на растрах).
Обычно, конечно, в GEE подключается нейросетевая модель, обученная в TF, но никто не запрещает использовать и другие модели. В нашем случае TF
хорош еще и тем, что в нем очень удобно производить оптимизацию параметров (собственно, для чего TF и создавался) -- очень распространенная задача в анализе ДЗЗ.

Но при выносе требуемой нам модели на уровень TF возникают сложности, связанные с тем, что в TF очень неудобно работать с отдельными каналами и растрами. По большому счету все, с чем человек
имеет дело при работе с TF - это многомерный массив. До тех пор, пока программисту не нужно обрабатывать отдельные измерения массива (в нашем случае - каналы) по специфическим
схемам обработки, все будет хорошо, но как только требуется достучаться до отдельного канала, приходится писать что-то вроде `Image[:, :, band_number, ;, ....]` и код очень быстро
замусовривается и становится нечитаемым.

Бороться с подобным можно, создавая объекты-обертки и организуя в них доступ к отдельным срезам данных. Выглядит это как-то так:
```{Python}
class YamazakiModel:
  def __init__(self, scene_count, band_names=['green','red','nir','swir1','tir2']):

    self.scene_count = scene_count
    self.band_names = band_names

    self.SCALE = tf.constant(15.0)
...   
    # Перечисляются параметры модели, которые нужно оптимизировать:
    # NDLI PARAMS
    self.NDLI_MIN = tf.Variable(0.0)
    self.NDLI_MAX = tf.Variable(0.5)
...

    # Прописываются свойства доступа к отдельным каналам
    @property
    def scene_axis(self):
      return 1

    @property
    def band_axis(self):
      return 2

    @property
    def green_idx(self):
      return self.band_names.index('green')
...

    # Доступ каналам:
    def _band(self, sample, index):
      return sample[:, :, index, :, :]

    def green(self, sample):
      return self._band(sample, self.green_idx)
...

    # Использование в самой модели
    def ndli(self, sample):
      red = self.red(sample)
      nir = self.nir(sample)
      green = self.green(sample)
      swir = self.swir(sample)

      gr = tf.math.minimum(red, green)
      ns = tf.math.maximum(nir, swir)

    def f_ndli(self, sample):
      ndli = self.ndli(sample)
      k = 1.0/(self.NDLI_MIN-self.NDLI_MAX)
      b = -self.NDLI_MAX *  k
      result = k * ndli + b
    
      result = tf.math.maximum(result, 0.0);
      result = tf.math.minimum(result, 1.0);
      return result
...

```

В конечном итоге за счет написания подобных оберток сам процесс подбора параметров становится более-менее комфортным. Но зато:

 * оберточного кода нужно очень много, по сути приходится писать чуть ли не свою растровую ГИС, но только на массивах;
 * оберточный код тоже довольно сложен: все более-менее прямолинейно до тех пор, пока не появляется свертка или аггрегация
 по одной из размерностей, в результате чего  меняется размерность массива и вся нумерация каналов летит к чертям.

Выигрыш же от использования связки GEE+TF в этой задаче не очень большой -- тайловая архитектура никуда не девается. Правда,
за счет внешнего кода мы можем играть размерами скользящего окна при обработке, но это не дает кардинального улучшения.

Из прочих минусов - отсутствие типично ГИСовских операций типа поддержки проекций и растров с различным разрешением пикселя.


## GRASS GIS

Еще один тестировавшийся вариант -- посчитать все на GRASS GIS. Плюсы очевидны:

 * полноценная ГИС с развитым инструментарием (нет проблем ни с зональной статистикой, ни с преобразованиями);
 * большие возможности скриптовой обработки;
 * встроенные классификаторы и возможноть подключения внешних (например, того же TF).

Минусы так же очевидны:

 * неудобно работать с большими данными, например, для параллельной обработки приходится в явном виде разбивать территорию на части
 (правда, в из-за ограничений по памяти в GEE в конечном итоге также приходится бить территорию на куски);
 * нужно хранить данные локально - огромный минус по сравнению с GEE, где получение данных происходит прозрачно для пользователя; в
 итоге нужно организовывать локальное хранилище данных и скачивать десятки террабайт снимков
 * считаешь все на своем железе, от которого и зависит, хватит ли ресурсов на обработку.


## Выводы

А выводов как таковых не будет, это скорее заметки на память по свежим следам.

Можно лишь сказать, что пока проклевывается такое грубое правило -- если нет ограничений на используемое ПО, тогда

 * если задача требует попискельного подхода, то лучшее ее решать в GEE;
 * если нужно работать с небольшими окрестностями пикселей (грубо до 200 пикселей), то тоже работаем GEE, а при необходимости подключаем TF;
 * если нужно аггрегировать данные в пространстве или работать с разнородными данными,
 тогда лучше играет связка GEE+GRASS - подготовка данных к анализу производится в GEE, затем экспорт полученных результатов и последующий анализ их в GRASS GIS.




